{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sezin/.local/share/virtualenvs/dsa-DC4ML-_HMLejDF/lib/python3.7/site-packages/chainer-6.0.0a1-py3.7.egg/chainer/_environment_check.py:41: UserWarning: Accelerate has been detected as a NumPy backend library.\n",
      "vecLib, which is a part of Accelerate, is known not to work correctly with Chainer.\n",
      "We recommend using other BLAS libraries such as OpenBLAS.\n",
      "For details of the issue, please see\n",
      "https://docs.chainer.org/en/stable/tips.html#mnist-example-does-not-converge-in-cpu-mode-on-mac-os-x.\n",
      "\n",
      "Also note that Chainer does not officially support Mac OS X.\n",
      "Please use it at your own risk.\n",
      "\n",
      "  ''')  # NOQA\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import imdb \n",
    "import pandas as pd\n",
    "#from error_generator import Explicit_Missing_Value\n",
    "#from error_generator import Implicit_Missing_Value\n",
    "#from error_generator import White_Noise\n",
    "#from error_generator import Gaussian_Noise\n",
    "from error_generator import Random_Active_Domain\n",
    "from error_generator import Similar_Based_Active_Domain\n",
    "from error_generator import Typo_Keyboard\n",
    "from error_generator import Typo_Butterfingers\n",
    "from error_generator import Word2vec_Nearest_Neighbor\n",
    "from error_generator import Value_Selector\n",
    "from error_generator import List_selected\n",
    "from error_generator import Read_Write\n",
    "from error_generator import Error_Generator\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LassoCV\n",
    "from yellowbrick.regressor import AlphaSelection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "anime_data = pd.read_csv(\"../../new_anime_data1.csv\", index_col=0)\n",
    "\n",
    "anime_data['episodes'] = anime_data['episodes'].replace('Unknown', np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = []\n",
    "l2 = []\n",
    "l3 = []\n",
    "\n",
    "\n",
    "anime_data['genre'].fillna('',  inplace=True)\n",
    "anime_data['overview'].fillna('',  inplace=True)\n",
    "anime_data['type'].fillna('',  inplace=True)\n",
    "for index, row in anime_data.iterrows():\n",
    "    item = row['genre']\n",
    "    if(pd.isnull(item)):\n",
    "            item =\"\"\n",
    "    else:\n",
    "        if isinstance(item, (list, tuple)):\n",
    "            item = ','.join(item)\n",
    "        else:\n",
    "            item = item.replace(\" \",\"\")\n",
    "            item = item.replace(\"[\",\"\")\n",
    "            item = item.replace(\"]\",\"\")\n",
    "            item = item.replace(\"'\",\"\")\n",
    "    l1.append(item) \n",
    "      \n",
    "\n",
    "for index, row in anime_data.iterrows():\n",
    "    item = row['overview']\n",
    "    if(pd.isnull(row['overview'])):\n",
    "            item = \"\"\n",
    "    else:\n",
    "       # for item in anime_data['overview']:\n",
    "            if isinstance(item, (list, tuple)):\n",
    "                item = ','.join(item)\n",
    "            else:\n",
    "                item = item.replace(\"[\",\"\")\n",
    "                item = item.replace(\"]\",\"\")\n",
    "    l2.append(item) \n",
    "\n",
    "for index, row in anime_data.iterrows():\n",
    "    item = row['type']\n",
    "    if(pd.isnull(row['type'])):\n",
    "        item = np.nan\n",
    "    else:    \n",
    "        if \"movie\" in item:\n",
    "            item = \"movie\"\n",
    "        else:\n",
    "            item = \"tv series\"\n",
    "    l3.append(item)\n",
    "\n",
    "    \n",
    "    \n",
    "anime_data['genre'] = l1   \n",
    "anime_data['overview'] = l2\n",
    "anime_data['type'] = l3\n",
    "\n",
    "#drop dublicate\n",
    "anime_data.drop_duplicates(inplace = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_train, anime_test = train_test_split(anime_data, test_size=0.2)\n",
    "anime_test.to_csv(\"testDataset.csv\", index = False,\n",
    "                  columns = ['anime_id', 'name','genre','type', 'episodes','rating', 'members', 'overview'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_generater(dataset, method, n, ignored_columns):\n",
    "\n",
    "    myselector=List_selected()\n",
    "\n",
    "    mygen=Error_Generator()\n",
    "\n",
    "    new_dataset=mygen.error_generator(method_gen=method,selector=myselector,percentage=n,dataset=dataset,mute_column = ignored_columns)\n",
    "    \n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Change according to Typo_Keyboard method ---------------\n",
      "\n",
      "row: 278 col: 2 : 'Animation' changed to 'nnmmqr'  \n",
      "row: 225 col: 2 : 'Action,Adventure,Mecha,Sci-Fi' changed to 'AAvbvvrnnwNw,,k--FF'  \n",
      "row: 94 col: 2 : 'Cars,Shounen,Sports' changed to 'CCaass,,SSlbwmSSlegd'  \n",
      "row: 142 col: 2 : 'Action,Adventure,Fantasy,Shounen' changed to 'Qttub,,fdmyrFFaannttss,,Zhhoouujeenn'  \n",
      "row: 326 col: 2 : 'Drama,Music,Romance' changed to 'DDtaans,,Kyssx,,Fpsd'  \n",
      "row: 12 col: 2 : 'Hentai' changed to 'HHeettqii'  \n",
      "row: 363 col: 2 : 'Action,Comedy,Historical,Parody,Samurai,Sci-Fi,Shounen' changed to 'AAccoo,,CCpdessifllPPoodd,,SSaakrrq,,ZcciiuSSboobm'  \n",
      "row: 399 col: 2 : 'Kids,Music' changed to 'KKksss,,MMuuwcc'  \n",
      "row: 145 col: 2 : 'Drama,Romance' changed to 'aaEpkaannccw'  \n",
      "row: 374 col: 2 : 'Ecchi,Music' changed to 'Rccbov'  \n",
      "row: 356 col: 2 : 'Animation,Comedy,Drama' changed to 'msgiip,,CCpddyy,,Sen'  \n",
      "row: 48 col: 2 : 'Adventure' changed to 'Qgdmttuueee'  \n",
      "row: 60 col: 2 : 'Comedy,Drama,Romance' changed to 'Vk,,DDeqq,,RRkaaccd'  \n",
      "row: 384 col: 2 : 'Adventure,Sci-Fi,Sport' changed to 'SddvveebttuufrDxuCppirrg'  \n",
      "row: 157 col: 2 : 'Adventure,Comedy,Fantasy,Mystery,Sci-Fi,Shounen' changed to 'nnit,,oorddyyaannttaasshddyy,,Av--oSSr'  \n",
      "row: 188 col: 2 : 'Hentai,Yuri' changed to 'HHeennUuuii'  \n",
      "row: 25 col: 2 : 'Comedy,SliceofLife' changed to 'ooneexyyWllkcceelKoffee'  \n",
      "row: 252 col: 2 : 'Animation,Sci-Fi' changed to 'jiiaaonnSSv--u'  \n",
      "row: 365 col: 2 : 'Animation,Adventure,Fantasy' changed to 'AAjnqriinnddcwnnyirrrFFaass'  \n",
      "row: 134 col: 2 : 'Adventure,Drama,Sci-Fi' changed to 'AAvvttjrr,,rraaq,,Aiiu'  \n",
      "row: 291 col: 2 : 'Animation,Adventure,Comedy' changed to 'onttoonn,,AAeennifwnrfyy'  \n",
      "row: 176 col: 2 : 'Comedy,Historical,Seinen' changed to 'irHHudyprrccaao,,SSree'  \n",
      "row: 110 col: 2 : 'Drama,Shounen,Sports' changed to 'Ftmmq,,bnnoirrss'  \n",
      "row: 369 col: 2 : 'Drama,Fantasy,Mystery,Romance,School' changed to 'tsmmFFsnnyaayy,,MMssrwyyEoommaafDxhhoooo'  \n",
      "row: 177 col: 2 : 'Animation,Action,Adventure,Fantasy' changed to 'ummonn,,Sxym,,ejit,,FFaabsau'  \n",
      "row: 246 col: 2 : 'Comedy,Sports' changed to 'FmmeeddyyDooorra'  \n",
      "row: 274 col: 2 : 'Comedy' changed to 'kddt'  \n",
      "row: 256 col: 2 : 'Adventure,Comedy,Historical,Kids' changed to 'AAednnttuuteeCCneefuBkrrrufaa,,KKsd'  \n",
      "row: 137 col: 2 : 'Animation,Short' changed to 'QiinaaiioonnSSoor'  \n",
      "row: 111 col: 2 : 'Action,Mecha,Military,Shounen' changed to 'AAxttnn,,Nccjq,,llaa,,yynneeb'  \n",
      "row: 165 col: 2 : 'Animation,Family,Fantasy,Music' changed to 'AAiiaayjFFaammllh,,aannttaasst,,MMiwcc'  \n",
      "row: 158 col: 2 : 'Adventure,Comedy,Fantasy' changed to 'vvrnnttuuee,,Fpnddyy,,FFaayaaw'  \n",
      "row: 378 col: 2 : 'Animation,Comedy,Fantasy' changed to 'QnniimmaattnnCCoowdd,,aaj'  \n",
      "row: 55 col: 2 : 'Sports' changed to 'ppfd'  \n",
      "row: 120 col: 2 : 'Hentai' changed to 'Grnnru'  \n",
      "row: 346 col: 2 : 'Hentai' changed to 'Bdnnii'  \n",
      "row: 318 col: 2 : 'Music' changed to 'Kisscc'  \n",
      "row: 230 col: 2 : 'Animation,Action,Fantasy,Game-Show,Sci-Fi' changed to 'SjnAAfgiilm,,qjttssyyqnwbiww,,ZoG'  \n",
      "row: 344 col: 2 : 'Comedy,Romance,School,Shounen' changed to 'XoordduRRpmmnnee,,Dhhoo,,Ahhiuunndj'  \n",
      "row: 275 col: 2 : 'Animation,Comedy' changed to 'AAnnmmqyooom,,CCpddyy'  \n",
      "row: 117 col: 2 : 'Action' changed to 'cculnn'  \n",
      "row: 283 col: 2 : 'Comedy' changed to 'inyy'  \n",
      "row: 152 col: 2 : 'Animation,Drama,Horror,Mystery' changed to 'biiii,,Xtaaaa,,errirryyssh'  \n",
      "row: 248 col: 2 : 'Short' changed to 'SSge'  \n",
      "row: 143 col: 2 : 'Drama,Mystery' changed to 'tqaa,,MMtaydt'  \n",
      "row: 229 col: 2 : 'Comedy,Drama,Romance' changed to 'CCoommwtDDaaqmmsx'  \n",
      "row: 6 col: 2 : 'Animation' changed to 'AAnnkmmaa'  \n",
      "row: 373 col: 2 : 'Comedy,Sports' changed to 'CCmmyyZpplr'  \n",
      "row: 174 col: 2 : 'Comedy,Romance' changed to 'Fyy,,sd'  \n",
      "row: 39 col: 2 : 'Fantasy,Kids' changed to 'aamyaaaKKdd'  \n",
      "row: 180 col: 2 : 'Drama,Kids' changed to 'aammq,,kddz'  \n",
      "row: 126 col: 2 : 'Animation,Action,Sci-Fi' changed to 'biikaaoonn,,Siib,,SScciiCii'  \n",
      "row: 159 col: 2 : 'Animation,Short,Horror' changed to 'nniittiilj,,jlrrg,,Bloo'  \n",
      "row: 224 col: 2 : 'Comedy' changed to 'oommdyy'  \n",
      "row: 46 col: 2 : 'Animation,Short' changed to 'Qmkqkoonn,,Zpett'  \n",
      "row: 332 col: 2 : 'Animation,Short,Drama,Music' changed to 'AAnniimmqttiinn,,blrr,,DDaaaa,,Kj'  \n",
      "row: 51 col: 2 : 'Adventure,Comedy,Fantasy,Kids' changed to 'Qddvvnnyje,,FoommhnngayyMxss'  \n",
      "row: 80 col: 2 : 'Seinen,SliceofLife' changed to 'SSdiiw,,frii'  \n",
      "row: 81 col: 2 : 'Ecchi' changed to 'EEcchhii'  \n",
      "row: 69 col: 2 : 'Hentai' changed to 'HHwnnysk'  \n",
      "row: 97 col: 2 : 'Kids,Music' changed to 'KKiisNizkx'  \n",
      "row: 164 col: 2 : 'Action,Fantasy,Shounen,SuperPower,Supernatural,Vampire' changed to 'Sxgsnnys,,Dboojnnrb,,uuoweierrieerrjryeqmmoiirr'  \n",
      "row: 101 col: 2 : 'Documentary,Music' changed to 'ElvnnngaarrhMMssiiv'  \n",
      "row: 279 col: 2 : 'Animation,Action,Comedy' changed to 'mkmmooSccrpm,,Voonh'  \n",
      "row: 64 col: 2 : 'Animation,Comedy,Drama' changed to 'Smiirunn,,CCoommdeyyEtsmms'  \n",
      "row: 166 col: 2 : 'Animation,Comedy,Family' changed to 'Qbaaoo,,VoorxFFqiillu'  \n",
      "row: 271 col: 2 : 'Animation,Drama' changed to 'AAbyuoonn,,Xsaa'  \n",
      "row: 195 col: 2 : 'Adventure,Comedy,Drama' changed to 'SddjuuVoonweyy,,aammaa'  \n",
      "row: 141 col: 2 : 'Animation,Action,Drama,Sci-Fi,Thriller,War' changed to 'Sjiittunn,,AAvkoonn,,DDfqf--FFii,,bkeeEaae'  \n",
      "row: 16 col: 2 : 'Animation,Short,Comedy' changed to 'AAnniikttiii,,SShhoott,,Fpddh'  \n",
      "row: 58 col: 2 : 'Action,Adventure,Animation,Sci-Fi,Thriller' changed to 'QccttnnevvQbkmmsgoo,,AG,,Rbfkll'  \n",
      "row: 235 col: 2 : 'Action,Horror,Sci-Fi,Thriller' changed to 'ttooob,,oorrtoorr,,SSxiiFFuGgrriilleerr'  \n",
      "row: 2 col: 2 : 'Comedy,Fantasy' changed to 'CCpduttssu'  \n",
      "row: 187 col: 2 : 'Comedy,Drama,Josei,Romance,SliceofLife' changed to 'mmf,,FtsJJooaii,,RRooaajxSSlLLur'  \n",
      "row: 197 col: 2 : 'Hentai' changed to 'HHr'  \n",
      "row: 82 col: 2 : 'Drama,Ecchi,Romance,School' changed to 'rrkq,,vhh,,Emmqnncc,,Ahhoopll'  \n",
      "row: 385 col: 2 : 'Comedy' changed to 'CCimmeet'  \n",
      "row: 217 col: 2 : 'Adventure,Comedy' changed to 'Swbrrd,,CCkreyy'  \n",
      "row: 136 col: 2 : 'Animation,Comedy' changed to 'kaalmCCoommwt'  \n",
      "row: 14 col: 2 : 'Drama' changed to 'tqaa'  \n",
      "row: 218 col: 2 : 'Action,Adventure,Comedy,Drama,Romance,Sci-Fi' changed to 'AAccooobQsgeennttteeCCnwsyymms,,RRoonmdu--ii'  \n",
      "row: 284 col: 2 : 'Animation,Comedy,Drama,Romance' changed to 'Qnniiqttkpnn,,Xpneeddu,,Sfaamm,,RRiee'  \n",
      "row: 263 col: 2 : 'Animation,Short,Comedy' changed to 'Smiikaagp,,SSooglmm'  \n",
      "row: 86 col: 2 : 'Sci-Fi' changed to 'vFFo'  \n",
      "row: 306 col: 2 : 'Drama,Josei' changed to 'kaa,,d'  \n",
      "row: 203 col: 2 : 'Action,Adventure,Drama,Mystery,Sci-Fi' changed to 'AAiioonn,,AAvvjttuueEfq,,tssttrryy,,SSCii'  \n",
      "row: 71 col: 2 : 'Animation,Short,Fantasy' changed to 'Smmiipnn,,SSjootttRqs'  \n",
      "row: 239 col: 2 : 'Animation,Short,Comedy' changed to 'Qoksgp,,SSyrry,,Xoorddyy'  \n",
      "row: 390 col: 2 : 'Drama' changed to 'DDrrsaa'  \n",
      "row: 259 col: 2 : 'SliceofLife,Supernatural' changed to 'oiixeeooffLLii,,SSjppnnk'  \n",
      "row: 186 col: 2 : 'Comedy,Parody,SuperPower' changed to 'CClyy,,eAywrrPPeee'  \n",
      "row: 216 col: 2 : 'Action,Comedy,MartialArts,School,Shounen' changed to 'ccgub,,Voorf,,rrttiisStywSScciooohhoonn'  \n",
      "row: 208 col: 2 : 'Action,Comedy,Kids,Shounen,SuperPower' changed to 'Qccttiipnn,,Vineeddu,,KKkdd,,SShhooinnnnyppeefPPwwe'  \n",
      "row: 294 col: 2 : 'Comedy,Kids' changed to 'CCieexddw'  \n",
      "row: 388 col: 2 : 'Action,Mecha' changed to 'w'  \n",
      "row: 139 col: 2 : 'Comedy,Ecchi,Fantasy,Harem,Romance,School,Sci-Fi,Supernatural' changed to 'CCookeexEEvFFaattaawyyYeeTlmmfwSSxhhooo,,vFF,,SSppeejaattyaall'  \n",
      "row: 238 col: 2 : 'Comedy,Parody,Sci-Fi' changed to 'mm,,Orrooeu,,Zii--FFu'  \n",
      "row: 88 col: 2 : 'Animation,Drama,Family,Fantasy,Romance' changed to 'AAnniiaayiiljXk,,FFaammk,,FFaabsyyRRoommaajvee'  \n",
      "row: 372 col: 2 : 'Drama,Kids' changed to 'FqIddss'  \n",
      "row: 127 col: 2 : 'Animation,Short' changed to 'AAkkqgSShhooty'  \n",
      "row: 168 col: 2 : 'Action,Animation,Sci-Fi' changed to 'ttnnQbummqkpm,,Wvo'  \n",
      "row: 172 col: 2 : 'Action,Fantasy,Supernatural' changed to 'Sccgiipmttaayypprrjaattjrraa'  \n",
      "row: 107 col: 2 : 'Animation,Comedy' changed to 'AAkmmaaolj,,CCpmmdh'  \n",
      "row: 74 col: 2 : 'Comedy,Fantasy,Kids' changed to 'CCoommfyy,,CaamttaaztLiidd'  \n",
      "row: 296 col: 2 : 'Animation,Adventure,Comedy,Family,Fantasy,Sci-Fi' changed to 'iimmqiip,,bttfee,,Xoommeedd,,FFaakllyy,,smttssuSSii--Ru'  \n",
      "row: 368 col: 2 : 'School' changed to 'SShh'  \n",
      "row: 310 col: 2 : 'Animation,Short' changed to 'Sbuaattunngooett'  \n",
      "row: 316 col: 2 : 'Action,Adventure,Comedy,Ecchi,Mecha,Sci-Fi,Space' changed to 'Sttooo,,AAddcdnnguurrr,,l,,WcchhiiMMeeyFFk,,Acc'  \n",
      "row: 162 col: 2 : 'Comedy,Psychological' changed to 'CCpmmdd,,Ossccols'  \n",
      "row: 357 col: 2 : 'Hentai' changed to 'Gnnttaa'  \n",
      "row: 250 col: 2 : 'Animation,Comedy,Fantasy' changed to 'AAmiiaaiioommwuFFmqssyy'  \n",
      "row: 205 col: 2 : 'Comedy' changed to 'CCineefyy'  \n",
      "row: 7 col: 2 : 'Animation' changed to 'roonn'  \n",
      "row: 302 col: 2 : 'Animation,Comedy' changed to 'Smmaarii,,peet'  \n",
      "row: 394 col: 2 : 'Animation' changed to 'kqrkoob'  \n",
      "row: 84 col: 2 : 'Hentai' changed to 'HHnnaa'  \n",
      "row: 194 col: 2 : 'Comedy,Drama' changed to 'VimmyySrrmm'  \n",
      "row: 383 col: 2 : 'Animation,Drama,Family,Romance' changed to 'SmmqttooDDsmmaa,,mmiillyy,,qnnee'  \n",
      "row: 370 col: 2 : 'Animation,Short,Comedy,Fantasy,Musical' changed to 'miinsgkoonn,,pttt,,Fpmmsyy,,qraassccqo'  \n",
      "row: 54 col: 2 : 'Hentai' changed to 'HHeennttaau'  \n",
      "row: 336 col: 2 : 'Drama,Historical,Sports' changed to 'DDaammHHagpeoccaak,,orra'  \n",
      "row: 103 col: 2 : 'Animation,Adventure,Comedy,Sci-Fi' changed to 'Snniiaattii,,AAgeeieinwucco--Ru'  \n",
      "row: 99 col: 2 : 'Action,Crime,Drama,Sci-Fi' changed to 'AAccttuoo,,CCDDrraamm,,SSviiR'  \n",
      "row: 133 col: 2 : 'Animation,Drama,Fantasy' changed to 'AAjiimmaarii,,DDrrqFFaannyzyy'  \n",
      "row: 389 col: 2 : 'Action,Adventure,Demons,Fantasy,Game,Kids,Magic,Sci-Fi,Supernatural' changed to 'riiinnAAcdnnguueeEdpnn,,nnttq,,HsrKKf,,KvvSSxiorrnnqrrrs'  \n",
      "row: 351 col: 2 : 'Comedy,Kids' changed to 'CCoorhKKddss'  \n",
      "row: 179 col: 2 : 'Adventure,Comedy,Magic,Romance,Shoujo' changed to 'vveegiee,,Fesggkcc,,RRkaaccee,,boouujj'  \n",
      "row: 65 col: 2 : 'Animation,Action,Adventure,Sci-Fi' changed to 'Snnnyoo,,AAccttiimSvvwjuueeWuo'  \n",
      "row: 1 col: 2 : 'Comedy,Drama,Romance' changed to 'ooees,,Xqn,,RRoonnccee'  \n",
      "row: 234 col: 2 : 'Comedy,Drama,Music' changed to 'XoonsDDtsmmaaNuussv'  \n",
      "row: 76 col: 2 : 'Animation,Action,Comedy,Romance,Sci-Fi' changed to 'bkttiioom,,SccroonnCCees,,RRlaamcccciiG'  \n",
      "row: 131 col: 2 : 'Animation,Short' changed to 'nnmmsttlnnWoo'  \n",
      "row: 299 col: 2 : 'Animation,Action,Adventure,Drama' changed to 'Snnyuoo,,AAttkoojQeejyirr,,Frraamm'  \n",
      "row: 30 col: 2 : 'Hentai' changed to 'HHttaao'  \n",
      "row: 173 col: 2 : 'Animation,Short' changed to 'AAkmmsyujSSjirr'  \n",
      "row: 104 col: 2 : 'Animation,Action,Comedy,Crime,Drama' changed to 'AAaayiioomAAccriioonnwxyyFeee,,aa'  \n",
      "row: 135 col: 2 : 'Animation,Short' changed to 'Qoaarj,,Attt'  \n",
      "row: 334 col: 2 : 'Comedy,Kids' changed to 'CCoonrIox'  \n",
      "row: 27 col: 2 : 'Comedy' changed to 'lmmfyy'  \n",
      "row: 19 col: 2 : 'Action,Adventure,Mecha,Romance,Sci-Fi,Shounen' changed to 'cciiinn,,AAtteeNbq,,RRpnsnnrcciiDnnnn'  \n",
      "row: 329 col: 2 : 'Hentai' changed to 'Bwnnq'  \n",
      "row: 244 col: 2 : 'Comedy,Romance,School,Shoujo' changed to 'CCindddyyRRookaam,,Axylll,,Zhhool'  \n",
      "row: 347 col: 2 : 'Drama,Historical' changed to 'Skaaossrrroaao'  \n",
      "row: 192 col: 2 : 'Action,Sci-Fi,Space' changed to 'froonn,,ZcciiGSSppaaccee'  \n",
      "row: 100 col: 2 : 'Animation' changed to 'Smiiqr'  \n",
      "row: 63 col: 2 : 'Fantasy,Magic' changed to 'FFqyaazyyNaagguf'  \n",
      "row: 21 col: 2 : 'Drama' changed to 'Eaak'  \n",
      "row: 240 col: 2 : 'Animation,Comedy' changed to 'AAmukqrupnn,,Vdu'  \n",
      "row: 40 col: 2 : 'Short,Action' changed to 'bttAAcclnn'  \n",
      "row: 151 col: 2 : 'Animation,Short,Action,Adventure,Comedy,Sci-Fi' changed to 'AAnnoaayoo,,SSy,,QccinnQddvvnnruurr,,VlneeddDGii'  \n",
      "row: 247 col: 2 : 'Action' changed to 'Qttom'  \n",
      "row: 122 col: 2 : 'Kids' changed to 'KKiidd'  \n",
      "row: 348 col: 2 : 'Comedy,School,Shounen' changed to 'uZfoo,,Zgiuuwj'  \n",
      "row: 119 col: 2 : 'Drama' changed to 'Xrraa'  \n",
      "row: 221 col: 2 : 'Animation,Action,Adventure,Family,Fantasy,Sci-Fi' changed to 'Qmsttuoovrkoo,,AAxvvmttfr,,CaakkllDsnnaayy,,SSku'  \n",
      "row: 178 col: 2 : 'Animation,Action,Fantasy,Sci-Fi' changed to 'Snniimmqgiii,,Sfttiilnn,,Rsttaa,,Zxu--FF'  \n",
      "row: 68 col: 2 : 'Animation,Short' changed to 'SiiaaolZoog'  \n",
      "row: 121 col: 2 : 'Documentary' changed to 'iccmmeebeyy'  \n",
      "row: 93 col: 2 : 'Harem,Hentai' changed to 'Baadmm,,jttii'  \n",
      "row: 49 col: 2 : 'Action,Adventure,Comedy,Mystery,Shounen' changed to 'Scciilnn,,eettf,,ookxh,,Kyydeehhhoobrnn'  \n",
      "row: 340 col: 2 : 'Kids' changed to 'Jiie'  \n",
      "row: 36 col: 2 : 'Adventure,Fantasy,Horror,Magic,Supernatural' changed to 'Qfvveennttuuw,,aanngqyyHHrrrrrr,,aakcc,,SSoebuull'  \n",
      "row: 124 col: 2 : 'Hentai' changed to 'eennttsii'  \n",
      "row: 182 col: 2 : 'Music' changed to 'Kuuw'  \n",
      "row: 108 col: 2 : 'Animation,Comedy,Fantasy' changed to 'Snnkmmaayoob,,Xmmwe,,FFttaayy'  \n",
      "row: 359 col: 2 : 'Crime,Drama,Thriller' changed to 'CCeiinee,,DDeaas,,jtkeerr'  \n",
      "row: 289 col: 2 : 'Animation,Comedy' changed to 'QjaapnnVee'  \n",
      "row: 219 col: 2 : 'Documentary,Biography,History,News' changed to 'ooccjyyy,,HiiootaabyyHHattluNNdwww'  \n",
      "row: 207 col: 2 : 'Drama,Romance,Yaoi' changed to 'DDrrsmmqRRnnf,,Uqii'  \n",
      "row: 38 col: 2 : 'Drama' changed to 'eq'  \n",
      "row: 277 col: 2 : 'Animation,Comedy,Drama,Romance' changed to 'AAnnkkaauoo,,Xlmmr,,aa,,inaaccee'  \n",
      "row: 129 col: 2 : 'Action,Comedy,Harem,Sci-Fi,Shounen,Space' changed to 'ttkpj,,CCiwyyHHqrreemmSSfiiGSShhoonneemSSppq'  \n",
      "row: 123 col: 2 : 'Historical,Kids' changed to 'BiidttksLiiss'  \n",
      "row: 331 col: 2 : 'Mystery,Police,Supernatural' changed to 'Kyytth,,PPpllvdSSoeennttaao'  \n",
      "row: 243 col: 2 : 'Adventure,Sci-Fi' changed to 'Svvjyirree,,SSxk--FFu'  \n",
      "row: 118 col: 2 : 'Comedy,Reality-TV' changed to 'mms,,RReesiigh--TTVV'  \n",
      "row: 22 col: 2 : 'Drama,Kids' changed to 'DDsmmKKss'  \n",
      "row: 361 col: 2 : 'Animation' changed to 'Sbsiilj'  \n",
      "row: 156 col: 2 : 'Animation,Comedy,Sci-Fi' changed to 'SommsttnnXoommreyy,,ii--'  \n",
      "row: 184 col: 2 : 'Animation,Short,Music' changed to 'AAokiinnDgi,,Kjov'  \n",
      "row: 20 col: 2 : 'Drama,Kids' changed to 'SKKii'  \n",
      "row: 290 col: 2 : 'Adventure,Kids' changed to 'ddwnnw,,Jess'  \n",
      "row: 304 col: 2 : 'Music' changed to 'MMuuw'  \n",
      "row: 314 col: 2 : 'Harem,Hentai' changed to 'HHe,,HHjys'  \n",
      "row: 83 col: 2 : 'Animation,Drama,Sport' changed to 'Smmqttooonn,,StaaSSoiftt'  \n",
      "row: 91 col: 2 : 'Animation,Comedy,Drama,Sport' changed to 'mmmaaroojookddtfskaa,,ppirry'  \n",
      "row: 335 col: 2 : 'Animation,Action,Comedy,Sci-Fi' changed to 'AAmmaaiioonnccroibXooeeii'  \n",
      "row: 313 col: 2 : 'Animation,Sci-Fi' changed to 'iiguinnWccii--Go'  \n",
      "row: 236 col: 2 : 'Drama' changed to 'Sfsaa'  \n",
      "row: 112 col: 2 : 'Documentary' changed to 'DDivuukrnnyqet'  \n",
      "row: 282 col: 2 : 'Comedy,Ecchi,Fantasy,Game' changed to 'oommrxyyWccvaabraass,,Hqmm'  \n",
      "row: 155 col: 2 : 'Short' changed to 'gett'  \n",
      "row: 341 col: 2 : 'Comedy,Fantasy,Kids' changed to 'CCmmeef,,FFaaryyLiiddss'  \n",
      "row: 213 col: 2 : 'Short,Comedy' changed to 'SSooett,,Xlneesyy'  \n",
      "row: 322 col: 2 : 'Drama,Historical,SliceofLife' changed to 'Ffaakqttfoaa,,SSllcciKkgr'  \n",
      "row: 114 col: 2 : 'Animation,Adventure,Family,Fantasy' changed to 'mmaaiipAAddvvdnnyeeeFFqiikhaagzt'  \n",
      "row: 273 col: 2 : 'Animation,Comedy' changed to 'junttul,,CCdd'  \n",
      "row: 317 col: 2 : 'Animation,Action,Adventure,Comedy,Drama,Fantasy,Horror,Thriller' changed to 'SnniittkoojSyimSddbrtmmeeyyEsnq,,Gaannywyy,,YirrtiTThhkollrr'  \n",
      "row: 327 col: 2 : 'Animation,Drama' changed to 'Qjoqgiioonn,,S'  \n",
      "row: 381 col: 2 : 'Kids,Supernatural' changed to 'kaSSuurrbqttes'  \n"
     ]
    }
   ],
   "source": [
    "# generate error in the test set\n",
    "new_dataset = error_generater(anime_test.values.tolist(), Typo_Keyboard(),50, ignored_columns = [0,1,3,4,5,6,7])\n",
    "Read_Write.write_csv_dataset(\"./{}.csv\".format(Typo_Keyboard().name), new_dataset)\n",
    "anime_test = pd.read_csv(\"./{}.csv\".format(Typo_Keyboard().name), \n",
    "                            names = ['anime_id', 'name','genre','type', 'episodes','rating', 'members', 'overview'])\n",
    "anime_test.to_csv(\"dirtyTestDataset.csv\", index = False,\n",
    "                  columns = ['anime_id', 'name','genre','type', 'episodes','rating', 'members', 'overview'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "def get_words(x):\n",
    "    bagofwords=[]\n",
    "    for i in x:\n",
    "        if i[1]=='NN':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='NNS':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='NNP':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='NNPS':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='JJ':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='JJR':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='JJS':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='RB':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='RBR':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='RBS':\n",
    "            bagofwords.append(i[0])\n",
    "    return bagofwords\n",
    "\n",
    "def clean_words(x):\n",
    "    b=nltk.pos_tag(nltk.word_tokenize(x))\n",
    "    result=get_words(b)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(train_data_set, test_data_set):\n",
    "    train_dummies = train_data_set.genre.str.get_dummies(',')\n",
    "    test_dummies = test_data_set.genre.str.get_dummies(',')\n",
    "    \n",
    "    #print(\"Train Dummies\",train_dummies.shape)    \n",
    "    #print(\"Test Dummies\",test_dummies.shape)\n",
    "    \n",
    "    #### ALİGN\n",
    "    train_dummies, test_dummies = train_dummies.align(test_dummies, axis=1, join='left')\n",
    "    \n",
    "    test_dummies.fillna(0, inplace=True)\n",
    "    \n",
    "    type_lb = LabelBinarizer()\n",
    "    fitted_type_lb = type_lb.fit(train_data_set.type.values)\n",
    "    X_train = type_lb.transform(train_data_set.type.values)\n",
    "    X_test  = type_lb.transform(test_data_set.type.values)\n",
    "    \n",
    "    dfOneHot_train = pd.DataFrame(X_train, columns = [\"movie/TVseries\" for i in range(X_train.shape[1])])\n",
    "    dfOneHot_test  = pd.DataFrame(X_test,  columns = [\"movie/TVseries\" for i in range(X_test.shape[1])])\n",
    "    \n",
    "    # Reset index to enable concat\n",
    "    train_data_set.reset_index(inplace=True)\n",
    "    dfOneHot_train.reset_index(inplace=True)\n",
    "    train_dummies.reset_index(inplace=True)\n",
    "    \n",
    "    test_data_set.reset_index(inplace=True)\n",
    "    dfOneHot_test.reset_index(inplace=True)\n",
    "    test_dummies.reset_index(inplace=True)\n",
    "    \n",
    "    train_data_set = pd.concat([train_data_set, dfOneHot_train], axis=1, join=\"inner\")\n",
    "    train_data_set = pd.concat([train_data_set, train_dummies ], axis=1, join=\"inner\")\n",
    "\n",
    "    test_data_set = pd.concat([test_data_set, dfOneHot_test], axis=1)\n",
    "    test_data_set = pd.concat([test_data_set, test_dummies],  axis=1)\n",
    "    \n",
    "    test_data_set['movie/TVseries'].fillna(0, inplace=True)\n",
    "    train_data_set['movie/TVseries'].fillna(0, inplace=True)\n",
    "\n",
    "    return ([train_data_set, test_data_set])\n",
    "\n",
    "def feature_transformation(train_data_set, test_data_set):\n",
    "    \n",
    "    dummieset = get_dummies(train_data_set, test_data_set)\n",
    "    train_data_set = dummieset[0]\n",
    "    test_data_set = dummieset[1]\n",
    "        \n",
    "    #Bag of Words\n",
    "    summary_doc_train = train_data_set['overview'].fillna(\"\").map(clean_words)\n",
    "    summary_doc_train =summary_doc_train.apply(','.join)\n",
    "    \n",
    "    summary_doc_test = test_data_set['overview'].fillna(\"\").map(clean_words)\n",
    "    summary_doc_test =summary_doc_test.apply(','.join)\n",
    " \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    fitted_vectorizer = vectorizer.fit(summary_doc_train)\n",
    "    overview_feature_train = fitted_vectorizer.transform(summary_doc_train).toarray()\n",
    "    overview_feature_test = fitted_vectorizer.transform(summary_doc_test).toarray()\n",
    "\n",
    "    df_train = pd.DataFrame(overview_feature_train, columns = [\"word\"+ str(int(i)) for i in range(overview_feature_train.shape[1])])\n",
    "    train_data_set = pd.concat([train_data_set, df_train], axis=1)\n",
    "    \n",
    "    df_test = pd.DataFrame(overview_feature_test, columns = [\"word\"+ str(int(i)) for i in range(overview_feature_test.shape[1])])\n",
    "    test_data_set = pd.concat([test_data_set, df_test], axis=1)\n",
    "    \n",
    "    train_data_set = train_data_set.drop(columns=['anime_id', 'name', 'genre', 'overview', 'type'])\n",
    "    test_data_set = test_data_set.drop(columns=['anime_id', 'name', 'genre', 'overview', 'type'])\n",
    "    \n",
    "    #drop NaN values\n",
    "    train_data_set.dropna(inplace=True)\n",
    "    test_data_set.dropna(inplace=True)\n",
    "    \n",
    "    train_data_set.fillna(0, inplace=True)\n",
    "    test_data_set.fillna(0, inplace=True)\n",
    "    \n",
    "    return ([train_data_set, test_data_set])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "'''\n",
    "anime_train = feature_transformation(anime_train)\n",
    "anime_test = feature_transformation(anime_test)\n",
    "'''\n",
    "transformed_features = feature_transformation(anime_train, anime_test)\n",
    "\n",
    "anime_train = transformed_features[0]\n",
    "anime_test = transformed_features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1542, 7203)\n",
      "(389, 7203)\n"
     ]
    }
   ],
   "source": [
    "#anime_train = anime_train.dropna()\n",
    "print(anime_train.shape)\n",
    "print(anime_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_y_train = anime_train['rating']\n",
    "anime_X_train = anime_train.drop(columns=['rating'])\n",
    "\n",
    "anime_y_test = anime_test['rating']\n",
    "anime_X_test = anime_test.drop(columns=['rating'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sezin/.local/share/virtualenvs/dsa-DC4ML-_HMLejDF/lib/python3.7/site-packages/sklearn/feature_selection/univariate_selection.py:299: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "/Users/sezin/.local/share/virtualenvs/dsa-DC4ML-_HMLejDF/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/sezin/.local/share/virtualenvs/dsa-DC4ML-_HMLejDF/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/sezin/.local/share/virtualenvs/dsa-DC4ML-_HMLejDF/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1831: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1542, 7202)\n",
      "(389, 7202)\n",
      "(1542, 700)\n",
      "(389, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sezin/.local/share/virtualenvs/dsa-DC4ML-_HMLejDF/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/sezin/.local/share/virtualenvs/dsa-DC4ML-_HMLejDF/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression,k=700)#anime_X_test.shape[1]-1)\n",
    "features = selector.fit(anime_X_train, anime_y_train)\n",
    "\n",
    "# summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "#print(fit.scores_)\n",
    "\n",
    "print(anime_X_train.shape)\n",
    "print(anime_X_test.shape)\n",
    "anime_X_train = features.transform(anime_X_train)\n",
    "anime_X_test = features.transform(anime_X_test)\n",
    "print(anime_X_train.shape)\n",
    "print(anime_X_test.shape)\n",
    "\n",
    "scaler = StandardScaler() \n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "anime_X_train = scaler.fit_transform(anime_X_train)  \n",
    "anime_X_test = scaler.transform(anime_X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Testing - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, dataset, label):\n",
    "    clf = model\n",
    "    clf.fit(dataset, label)\n",
    "    return clf\n",
    "\n",
    "def testing_evaluation(model, testset):\n",
    "    # Make predictions using the testing set\n",
    "    anime_y_pred = model.predict(testset)\n",
    "\n",
    "    # The mean absolute error\n",
    "    print(\"Mean absolute error: %.2f\" % np.sqrt(mean_absolute_error(anime_y_test, anime_y_pred)))\n",
    "\n",
    "    # The mean squared error\n",
    "    print(\"Mean squared error: %.2f\" % np.sqrt(mean_squared_error(anime_y_test, anime_y_pred)))\n",
    "\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print('Variance score: %.2f' % r2_score(anime_y_test, anime_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 1620328.82\n",
      "Mean squared error: 15749894075709.87\n",
      "Variance score: -231310727420974104766840832.00\n"
     ]
    }
   ],
   "source": [
    "clf = training(model = linear_model.LinearRegression(), dataset = anime_X_train, label= anime_y_train)\n",
    "testing_evaluation(clf, anime_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 1.04\n",
      "Mean squared error: 1.39\n",
      "Variance score: -0.81\n"
     ]
    }
   ],
   "source": [
    "clf = training(model = linear_model.Lasso(alpha=0.1), dataset = anime_X_train, label= anime_y_train)\n",
    "testing_evaluation(clf, anime_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Create a list of alphas to cross-validate against\\nalphas = np.logspace(-10, 1, 100)\\n\\n# Instantiate the linear model and visualizer\\nmodel = LassoCV(alphas=alphas, cv = 5)\\nvisualizer = AlphaSelection(model)\\n\\nvisualizer.fit(anime_X_train, anime_y_train)\\ng = visualizer.poof()\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Create a list of alphas to cross-validate against\n",
    "alphas = np.logspace(-10, 1, 100)\n",
    "\n",
    "# Instantiate the linear model and visualizer\n",
    "model = LassoCV(alphas=alphas, cv = 5)\n",
    "visualizer = AlphaSelection(model)\n",
    "\n",
    "visualizer.fit(anime_X_train, anime_y_train)\n",
    "g = visualizer.poof()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.699 0.793 0.695 0.731 0.701]\n",
      "Mean: 0.7238608658267057\n",
      "Standard deviation: 0.03695593570225408\n"
     ]
    }
   ],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "scores = cross_val_score(clf, anime_X_train, anime_y_train, scoring=\"neg_mean_squared_error\", cv=5) \n",
    "rmse_scores = np.sqrt(-scores)\n",
    "display_scores(rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search For Hyper Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sezin/.local/share/virtualenvs/dsa-DC4ML-_HMLejDF/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/sezin/.local/share/virtualenvs/dsa-DC4ML-_HMLejDF/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/sezin/.local/share/virtualenvs/dsa-DC4ML-_HMLejDF/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/sezin/.local/share/virtualenvs/dsa-DC4ML-_HMLejDF/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/sezin/.local/share/virtualenvs/dsa-DC4ML-_HMLejDF/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/sezin/.local/share/virtualenvs/dsa-DC4ML-_HMLejDF/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/sezin/.local/share/virtualenvs/dsa-DC4ML-_HMLejDF/lib/python3.7/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters are:  {'alpha': 0.1}\n",
      "The mean squared Error is: 0.53\n"
     ]
    }
   ],
   "source": [
    "def checkHP(model, folds, dataset, label):\n",
    "    parameters = {\n",
    "                   \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  }\n",
    "\n",
    "    gd_sr = GridSearchCV(estimator=model,  \n",
    "                         param_grid=parameters,\n",
    "                         scoring=\"neg_mean_squared_error\",\n",
    "                         cv=folds)\n",
    "\n",
    "    gd_sr.fit(dataset, label)  \n",
    "    \n",
    "    best_parameters = gd_sr.best_params_  \n",
    "    print(\"best parameters are: \", best_parameters)\n",
    "\n",
    "    best_result = gd_sr.best_score_  \n",
    "    print(\"The mean squared Error is: %.2f\" % -best_result) \n",
    "    \n",
    "checkHP(clf, 5, anime_X_train, anime_y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 1.04\n",
      "Mean squared error: 1.39\n",
      "Variance score: -0.81\n"
     ]
    }
   ],
   "source": [
    "clf = training(model = linear_model.Lasso(alpha=0.1), dataset = anime_X_train, label= anime_y_train)\n",
    "testing_evaluation(clf, anime_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa-DC4ML",
   "language": "python",
   "name": "dsa-dc4ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
