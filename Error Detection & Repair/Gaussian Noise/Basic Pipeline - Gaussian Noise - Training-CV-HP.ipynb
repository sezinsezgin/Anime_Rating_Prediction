{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imdb \n",
    "import pandas as pd\n",
    "import random\n",
    "from pandas.tools.plotting import autocorrelation_plot\n",
    "from matplotlib import pyplot\n",
    "#from error_generator import Explicit_Missing_Value\n",
    "#from error_generator import Implicit_Missing_Value\n",
    "#from error_generator import White_Noise\n",
    "from error_generator import Gaussian_Noise\n",
    "from error_generator import Random_Active_Domain\n",
    "from error_generator import Similar_Based_Active_Domain\n",
    "from error_generator import Typo_Keyboard\n",
    "from error_generator import Typo_Butterfingers\n",
    "from error_generator import Word2vec_Nearest_Neighbor\n",
    "from error_generator import Value_Selector\n",
    "from error_generator import List_selected\n",
    "from error_generator import Read_Write\n",
    "from error_generator import Error_Generator\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LassoCV\n",
    "from yellowbrick.regressor import AlphaSelection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "anime_data = pd.read_csv(\"../../new_anime_data1.csv\", index_col=0)\n",
    "\n",
    "anime_data['episodes'] = anime_data['episodes'].replace('Unknown', np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l1 = []\n",
    "l2 = []\n",
    "l3 = []\n",
    "\n",
    "\n",
    "anime_data['genre'].fillna('',  inplace=True)\n",
    "anime_data['overview'].fillna('',  inplace=True)\n",
    "anime_data['type'].fillna('',  inplace=True)\n",
    "anime_data['episodes'].fillna(0,  inplace=True)\n",
    "anime_data['rating'].fillna(0,  inplace=True)\n",
    "for index, row in anime_data.iterrows():\n",
    "    item = row['genre']\n",
    "    if(pd.isnull(item)):\n",
    "            item =\"\"\n",
    "    else:\n",
    "        if isinstance(item, (list, tuple)):\n",
    "            item = ','.join(item)\n",
    "        else:\n",
    "            item = item.replace(\" \",\"\")\n",
    "            item = item.replace(\"[\",\"\")\n",
    "            item = item.replace(\"]\",\"\")\n",
    "            item = item.replace(\"'\",\"\")\n",
    "    l1.append(item) \n",
    "      \n",
    "\n",
    "for index, row in anime_data.iterrows():\n",
    "    item = row['overview']\n",
    "    if(pd.isnull(row['overview'])):\n",
    "            item = \"\"\n",
    "    else:\n",
    "       # for item in anime_data['overview']:\n",
    "            if isinstance(item, (list, tuple)):\n",
    "                item = ','.join(item)\n",
    "            else:\n",
    "                item = item.replace(\"[\",\"\")\n",
    "                item = item.replace(\"]\",\"\")\n",
    "    l2.append(item) \n",
    "\n",
    "for index, row in anime_data.iterrows():\n",
    "    item = row['type']\n",
    "    if(pd.isnull(row['type'])):\n",
    "        item = np.nan\n",
    "    else:    \n",
    "        if \"movie\" in item:\n",
    "            item = \"movie\"\n",
    "        else:\n",
    "            item = \"tv series\"\n",
    "    l3.append(item)\n",
    "\n",
    "    \n",
    "    \n",
    "anime_data['genre'] = l1   \n",
    "anime_data['overview'] = l2\n",
    "anime_data['type'] = l3\n",
    "\n",
    "#drop dublicate\n",
    "anime_data.drop_duplicates(inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "anime_train, anime_test = train_test_split(anime_data, test_size=0.2)\n",
    "anime_test.to_csv(\"testDataset.csv\", index = False,\n",
    "                  columns = ['anime_id', 'name','genre','type', 'episodes','rating', 'members', 'overview'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample of the data before adding Gaussian Noise\n",
      "3026     9293\n",
      "964     11149\n",
      "7079      413\n",
      "6090     1566\n",
      "5120      283\n",
      "5192     1886\n",
      "831     76286\n",
      "7654      131\n",
      "7722      164\n",
      "Name: members, dtype: int64\n",
      "\n",
      "sample of the data after adding Gaussian Noise\n",
      "9017   -10809.559675\n",
      "3026    12395.940687\n",
      "964     -4666.676128\n",
      "7079    15775.765238\n",
      "6090   -14530.551749\n",
      "5120    -7709.772018\n",
      "5192    -5861.975257\n",
      "831     67055.819852\n",
      "7654    10042.161727\n",
      "7722     -576.880340\n",
      "Name: members, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3267: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = anime_train.members\n",
    "sample = anime_train.members[0:600]\n",
    "print(\"sample of the data before adding Gaussian Noise\")\n",
    "print(sample[1:10])\n",
    "mu, sigma = 0, 10000\n",
    "\n",
    "noise = np.random.normal(mu, sigma, 600)\n",
    "\n",
    "signal = sample + noise\n",
    "\n",
    "print(\"\\nsample of the data after adding Gaussian Noise\")\n",
    "print(signal[0:10])\n",
    "   \n",
    "anime_train.members.update(signal)\n",
    "\n",
    "anime_train.to_csv(\"dirtyTrainDataset.csv\", index = False,\n",
    "                  columns = ['anime_id', 'name','genre','type', 'episodes','rating', 'members', 'overview'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot with Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16e57730>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.scatter(sample.sort_values(), signal.sort_values(), linewidth=1, linestyle=\"-\", c=\"b\")\n",
    "\n",
    "plt.plot(df.sort_values(), anime_train.members, 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "def get_words(x):\n",
    "    bagofwords=[]\n",
    "    for i in x:\n",
    "        if i[1]=='NN':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='NNS':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='NNP':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='NNPS':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='JJ':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='JJR':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='JJS':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='RB':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='RBR':\n",
    "            bagofwords.append(i[0])\n",
    "        elif i[1]=='RBS':\n",
    "            bagofwords.append(i[0])\n",
    "    return bagofwords\n",
    "\n",
    "def clean_words(x):\n",
    "    b=nltk.pos_tag(nltk.word_tokenize(x))\n",
    "    result=get_words(b)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(train_data_set, test_data_set):\n",
    "    train_dummies = train_data_set.genre.str.get_dummies(',')\n",
    "    test_dummies = test_data_set.genre.str.get_dummies(',')\n",
    "    \n",
    "    #print(\"Train Dummies\",train_dummies.shape)    \n",
    "    #print(\"Test Dummies\",test_dummies.shape)\n",
    "    \n",
    "    #### ALÄ°GN\n",
    "    train_dummies, test_dummies = train_dummies.align(test_dummies, axis=1, join='left')\n",
    "    \n",
    "    test_dummies.fillna(0, inplace=True)\n",
    "    \n",
    "    type_lb = LabelBinarizer()\n",
    "    fitted_type_lb = type_lb.fit(train_data_set.type.values)\n",
    "    X_train = type_lb.transform(train_data_set.type.values)\n",
    "    X_test  = type_lb.transform(test_data_set.type.values)\n",
    "    \n",
    "    dfOneHot_train = pd.DataFrame(X_train, columns = [\"movie/TVseries\" for i in range(X_train.shape[1])])\n",
    "    dfOneHot_test  = pd.DataFrame(X_test,  columns = [\"movie/TVseries\" for i in range(X_test.shape[1])])\n",
    "    \n",
    "    \n",
    "    train_data_set = pd.concat([train_data_set, dfOneHot_train], axis=1, join=\"inner\")\n",
    "    train_data_set = pd.concat([train_data_set, train_dummies ], axis=1, join=\"inner\")\n",
    "\n",
    "    test_data_set = pd.concat([test_data_set, dfOneHot_test], axis=1)\n",
    "    test_data_set = pd.concat([test_data_set, test_dummies],  axis=1)\n",
    "    \n",
    "    test_data_set['movie/TVseries'].fillna(0, inplace=True)\n",
    "    train_data_set['movie/TVseries'].fillna(0, inplace=True)\n",
    "\n",
    "    return ([train_data_set, test_data_set])\n",
    "\n",
    "def feature_transformation(train_data_set, test_data_set):\n",
    "    \n",
    "    dummieset = get_dummies(train_data_set, test_data_set)\n",
    "    train_data_set = dummieset[0]\n",
    "    test_data_set = dummieset[1]\n",
    "        \n",
    "    #Bag of Words\n",
    "    summary_doc_train = train_data_set['overview'].fillna(\"\").map(clean_words)\n",
    "    summary_doc_train =summary_doc_train.apply(','.join)\n",
    "    \n",
    "    summary_doc_test = test_data_set['overview'].fillna(\"\").map(clean_words)\n",
    "    summary_doc_test =summary_doc_test.apply(','.join)\n",
    " \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    fitted_vectorizer = vectorizer.fit(summary_doc_train)\n",
    "    overview_feature_train = fitted_vectorizer.transform(summary_doc_train).toarray()\n",
    "    overview_feature_test = fitted_vectorizer.transform(summary_doc_test).toarray()\n",
    "\n",
    "    df_train = pd.DataFrame(overview_feature_train, columns = [\"word\"+ str(int(i)) for i in range(overview_feature_train.shape[1])])\n",
    "    train_data_set = pd.concat([train_data_set, df_train], axis=1)\n",
    "    \n",
    "    df_test = pd.DataFrame(overview_feature_test, columns = [\"word\"+ str(int(i)) for i in range(overview_feature_test.shape[1])])\n",
    "    test_data_set = pd.concat([test_data_set, df_test], axis=1)\n",
    "    \n",
    "    train_data_set = train_data_set.drop(columns=['anime_id', 'name', 'genre', 'overview', 'type'])\n",
    "    test_data_set = test_data_set.drop(columns=['anime_id', 'name', 'genre', 'overview', 'type'])\n",
    "    \n",
    "    #drop NaN values\n",
    "    train_data_set.dropna(inplace=True)\n",
    "    test_data_set.dropna(inplace=True)\n",
    "    \n",
    "    train_data_set.fillna(0, inplace=True)\n",
    "    test_data_set.fillna(0, inplace=True)\n",
    "    \n",
    "    return ([train_data_set, test_data_set])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "transformed_features = feature_transformation(anime_train, anime_test)\n",
    "\n",
    "anime_train = transformed_features[0]\n",
    "anime_test = transformed_features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 2453)\n",
      "(27, 2453)\n"
     ]
    }
   ],
   "source": [
    "#anime_train = anime_train.dropna()\n",
    "print(anime_train.shape)\n",
    "print(anime_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime_y_train = anime_train['rating']\n",
    "anime_X_train = anime_train.drop(columns=['rating'])\n",
    "\n",
    "anime_y_test = anime_test['rating']\n",
    "anime_X_test = anime_test.drop(columns=['rating'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 2452)\n",
      "(27, 2452)\n",
      "(32, 700)\n",
      "(27, 700)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pattern-3.6-py3.7.egg\\pattern\\text\\en\\..\\..\\..\\..\\sklearn\\feature_selection\\univariate_selection.py:299: RuntimeWarning: invalid value encountered in true_divide\n",
      "  corr /= X_norms\n",
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1831: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pattern-3.6-py3.7.egg\\pattern\\text\\en\\..\\..\\..\\..\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pattern-3.6-py3.7.egg\\pattern\\text\\en\\..\\..\\..\\..\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pattern-3.6-py3.7.egg\\pattern\\text\\en\\..\\..\\..\\..\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression,k=700)\n",
    "features = selector.fit(anime_X_train, anime_y_train)\n",
    "\n",
    "# summarize scores\n",
    "np.set_printoptions(precision=3)\n",
    "#print(fit.scores_)\n",
    "\n",
    "print(anime_X_train.shape)\n",
    "print(anime_X_test.shape)\n",
    "anime_X_train = features.transform(anime_X_train)\n",
    "anime_X_test = features.transform(anime_X_test)\n",
    "print(anime_X_train.shape)\n",
    "print(anime_X_test.shape)\n",
    "\n",
    "scaler = StandardScaler() \n",
    "\n",
    "# Apply transform to both the training set and the test set.\n",
    "anime_X_train = scaler.fit_transform(anime_X_train)  \n",
    "anime_X_test = scaler.transform(anime_X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - Testing - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, dataset, label):\n",
    "    clf = model\n",
    "    clf.fit(dataset, label)\n",
    "    return clf\n",
    "\n",
    "def testing_evaluation(model, testset):\n",
    "    # Make predictions using the testing set\n",
    "    anime_y_pred = model.predict(testset)\n",
    "\n",
    "    # The mean absolute error\n",
    "    print(\"Mean absolute error: %.2f\" % np.sqrt(mean_absolute_error(anime_y_test, anime_y_pred)))\n",
    "\n",
    "    # The mean squared error\n",
    "    print(\"Mean squared error: %.2f\" % np.sqrt(mean_squared_error(anime_y_test, anime_y_pred)))\n",
    "\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print('Variance score: %.2f' % r2_score(anime_y_test, anime_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 0.64\n",
      "Mean squared error: 0.50\n",
      "Variance score: -6.59\n"
     ]
    }
   ],
   "source": [
    "clf = training(model = linear_model.LinearRegression(), dataset = anime_X_train, label= anime_y_train)\n",
    "testing_evaluation(clf, anime_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 0.73\n",
      "Mean squared error: 0.56\n",
      "Variance score: -8.37\n"
     ]
    }
   ],
   "source": [
    "clf = training(model = linear_model.Lasso(alpha=0.1), dataset = anime_X_train, label= anime_y_train)\n",
    "testing_evaluation(clf, anime_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Create a list of alphas to cross-validate against\\nalphas = np.logspace(-10, 1, 100)\\n\\n# Instantiate the linear model and visualizer\\nmodel = LassoCV(alphas=alphas, cv = 5)\\nvisualizer = AlphaSelection(model)\\n\\nvisualizer.fit(anime_X_train, anime_y_train)\\ng = visualizer.poof()\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Create a list of alphas to cross-validate against\n",
    "alphas = np.logspace(-10, 1, 100)\n",
    "\n",
    "# Instantiate the linear model and visualizer\n",
    "model = LassoCV(alphas=alphas, cv = 5)\n",
    "visualizer = AlphaSelection(model)\n",
    "\n",
    "visualizer.fit(anime_X_train, anime_y_train)\n",
    "g = visualizer.poof()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.426 0.076 0.101 0.174 0.223]\n",
      "Mean: 0.20015489883566645\n",
      "Standard deviation: 0.12447324868607493\n"
     ]
    }
   ],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "scores = cross_val_score(clf, anime_X_train, anime_y_train, scoring=\"neg_mean_squared_error\", cv=5) \n",
    "rmse_scores = np.sqrt(-scores)\n",
    "display_scores(rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search For Hyper Parameter Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pattern-3.6-py3.7.egg\\pattern\\text\\en\\..\\..\\..\\..\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pattern-3.6-py3.7.egg\\pattern\\text\\en\\..\\..\\..\\..\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pattern-3.6-py3.7.egg\\pattern\\text\\en\\..\\..\\..\\..\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pattern-3.6-py3.7.egg\\pattern\\text\\en\\..\\..\\..\\..\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pattern-3.6-py3.7.egg\\pattern\\text\\en\\..\\..\\..\\..\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters are:  {'alpha': 0.1}\n",
      "The mean squared Error is: 0.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pattern-3.6-py3.7.egg\\pattern\\text\\en\\..\\..\\..\\..\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "c:\\users\\larat\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pattern-3.6-py3.7.egg\\pattern\\text\\en\\..\\..\\..\\..\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "def checkHP(model, folds, dataset, label):\n",
    "    parameters = {\n",
    "                   \"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  }\n",
    "\n",
    "    gd_sr = GridSearchCV(estimator=model,  \n",
    "                         param_grid=parameters,\n",
    "                         scoring=\"neg_mean_squared_error\",\n",
    "                         cv=folds)\n",
    "\n",
    "    gd_sr.fit(dataset, label)  \n",
    "    \n",
    "    best_parameters = gd_sr.best_params_  \n",
    "    print(\"best parameters are: \", best_parameters)\n",
    "\n",
    "    best_result = gd_sr.best_score_  \n",
    "    print(\"The mean squared Error is: %.2f\" % -best_result) \n",
    "    \n",
    "checkHP(clf, 5, anime_X_train, anime_y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 0.73\n",
      "Mean squared error: 0.56\n",
      "Variance score: -8.37\n"
     ]
    }
   ],
   "source": [
    "clf = training(model = linear_model.Lasso(alpha=0.1), dataset = anime_X_train, label= anime_y_train)\n",
    "testing_evaluation(clf, anime_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
